{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   4    6    8 ... 3594 3596 3598]\n"
     ]
    }
   ],
   "source": [
    "file = '17.csv'\n",
    "track = pd.read_csv(file)\n",
    "track.columns = ['frame', 'id', 'x', 'y', 'w', 'h', 'a', 'b', 'c', 'd', 't']\n",
    "frames = track['frame'].unique()\n",
    "# frames = frames[::2]\n",
    "print(frames)\n",
    "track = track[track['frame'].isin(frames)]\n",
    "\n",
    "# track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {0},\n",
       " 2: {2},\n",
       " 3: {3},\n",
       " 4: {4},\n",
       " 6: {6},\n",
       " 1: {1},\n",
       " 7: {7},\n",
       " 9: {9},\n",
       " 12: {12},\n",
       " 13: {13},\n",
       " 15: {15},\n",
       " 16: {16},\n",
       " 24: {24},\n",
       " 26: {26},\n",
       " 31: {31},\n",
       " 33: {33},\n",
       " 43: {43},\n",
       " 50: {50},\n",
       " 65: {65},\n",
       " 79: {79},\n",
       " 129: {129},\n",
       " 132: {132},\n",
       " 134: {134},\n",
       " 136: {136},\n",
       " 137: {137},\n",
       " 138: {138},\n",
       " 140: {140},\n",
       " 146: {146}}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonyms = {0: set([0])}\n",
    "for boad_id in track['id'].unique():\n",
    "    synonyms[boad_id] = set([boad_id])\n",
    "    \n",
    "\n",
    "synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frames = track['frame'].unique()\n",
    "# frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for frame in frames:\n",
    "#     frame_objects = track[track['frame'] == frame]\n",
    "#     print(len(frame_objects))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1 = np.zeros((720, 1280))\n",
    "img2 = np.zeros((720, 1280))\n",
    "x, y, w, h = 10, 10, 10, 10\n",
    "img1[y: y+h, x: x+w]=1\n",
    "img2[y: y+h, x: x+w]=1\n",
    "\n",
    "np.sum(np.multiply(img1, img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1798,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(frames.shape)\n",
    "frames = list(frames)\n",
    "frames_shifted = frames[:]\n",
    "frames_shifted.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = []\n",
    "for frame, frame_shifted in zip(frames[:-1], frames_shifted):\n",
    "#     print(frame, frame_shifted)\n",
    "    set1 = set(track[track['frame'] == frame]['id'].values)\n",
    "    set2 = set(track[track['frame'] == frame_shifted]['id'].values)\n",
    "#     print(set1)\n",
    "#     print(set2)\n",
    "    old = list(set1 - set2) # old objects\n",
    "    nuw = list(set2 - set1) # new objects\n",
    "#     sizes.append(len(set1 - set2))\n",
    "#     sizes.append(len(set2 - set1))\n",
    "    frame_data = track[track['frame'] == frame]\n",
    "    frame_shifted_data = track[track['frame'] == frame_shifted]\n",
    "    \n",
    "    max_overlap = 10\n",
    "    oo = 0\n",
    "    no = 0\n",
    "    for old_object in old:\n",
    "        old_attributes = frame_data[frame_data['id'] == old_object]\n",
    "        ox, oy, ow, oh = int(old_attributes['x']), int(old_attributes['y']), int(old_attributes['w']), int(old_attributes['h'])\n",
    "        for nuw_object in nuw:\n",
    "            nuw_attributes = frame_shifted_data[frame_shifted_data['id'] == nuw_object]\n",
    "            nx, ny, nw, nh = int(nuw_attributes['x']), int(nuw_attributes['y']), int(nuw_attributes['w']), int(nuw_attributes['h'])\n",
    "            \n",
    "            \n",
    "            \n",
    "            img1 = np.zeros((720, 1280))\n",
    "            img2 = np.zeros((720, 1280))\n",
    "            img1[oy: oy+oh, ox: ox+ow] = 1 \n",
    "            img2[ny: ny+nh, nx: nx+nw] = 1\n",
    "            \n",
    "            overlap = np.sum(np.multiply(img1, img2))\n",
    "            if overlap > max_overlap:\n",
    "                oo = old_object\n",
    "                no = nuw_object\n",
    "                # I should here remove the new object from the remaining comparsions \n",
    "                # but leave for now when cleaning the code\n",
    "            \n",
    "            synonyms[oo].add(no)\n",
    "            synonyms[no].add(oo)\n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "    \n",
    "    \n",
    "#     if len(old) == len(nuw) == 1:\n",
    "#         synonyms[old[0]].add(nuw[0])\n",
    "#         synonyms[nuw[0]].add(old[0])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "# print(max(size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type set is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-e298a1f32b6b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msynonyms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m's_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msynonyms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\mdefr\\anaconda3\\envs\\tensorflow2.0-gpu\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[1;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mindent\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mseparators\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m         default is None and not sort_keys and not kw):\n\u001b[1;32m--> 231\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mdefr\\anaconda3\\envs\\tensorflow2.0-gpu\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[1;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[1;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mdefr\\anaconda3\\envs\\tensorflow2.0-gpu\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[1;34m(self, o, _one_shot)\u001b[0m\n\u001b[0;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
      "\u001b[1;32mc:\\users\\mdefr\\anaconda3\\envs\\tensorflow2.0-gpu\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \"\"\"\n\u001b[1;32m--> 179\u001b[1;33m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[0;32m    180\u001b[0m                         f'is not JSON serializable')\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Object of type set is not JSON serializable"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "synonyms\n",
    "with open('s_' + file, 'w') as f:\n",
    "    f.write(json.dumps(dictionary, indent = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# track = track.iloc[0:-1:2, :]\n",
    "# len(track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frames = track['frame'].unique()\n",
    "# frames\n",
    "\n",
    "# print(frames.shape)\n",
    "# frames = list(frames)\n",
    "# frames_shifted = frames[:]\n",
    "# frames_shifted.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sizes = []\n",
    "# for frame, frame_shifted in zip(frames[:-1], frames_shifted):\n",
    "# #     print(frame, frame_shifted)\n",
    "#     set1 = set(track[track['frame'] == frame]['id'].values)\n",
    "#     set2 = set(track[track['frame'] == frame_shifted]['id'].values)\n",
    "#     print(set1)\n",
    "#     print(set2)\n",
    "#     old = list(set1 - set2) # old objects\n",
    "#     nuw = list(set2 - set1) # new objects\n",
    "# #     sizes.append(len(set1 - set2))\n",
    "# #     sizes.append(len(set2 - set1))\n",
    "\n",
    "#     if len(old) == len(nuw) == 1:\n",
    "#         synonyms[old[0]].add(nuw[0])\n",
    "#         synonyms[nuw[0]].add(old[0])\n",
    "        \n",
    "    \n",
    "# # print(max(size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synonyms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
